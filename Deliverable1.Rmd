---
title: "USED CAR PRICES CASE STUDY"
subtitle: 'Deliverable 2: PCA, CA and Clustering'
author: "Miquel Parra i Xavier Alaman"
date: \today
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
geometry: left=1.9cm,right=1.9cm,top=1.25cm,bottom=1.52cm
fontsize: 18pt
classoption: a4paper
editor_options: 
  chunk_output_type: console
---

# R libraries imports, useful functions and data loading

In this first section we will load all required packages and libraries, declare additional functions, and load our data.

## Load Required Packages

```{r, results='hide'}
# Load Required Packages: to be increased over the course
options(contrasts=c("contr.treatment","contr.treatment"))

requiredPackages <- c("effects","FactoMineR","car","missMDA","mvoutlier","chemometrics", "factoextra","RColorBrewer","ggplot2","dplyr","ggmap","ggthemes","knitr")

#use this function to check if each package is on the local machine
#if a package is installed, it will be loaded
#if any are not, the missing package(s) will be installed and loaded
package.check <- lapply(requiredPackages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)
  }
})
#verify they are loaded
search()

```

## Sample load

```{r, results='hide'}
# Clear plots
if(!is.null(dev.list())) dev.off()

# Clean workspace
rm(list=ls())

# Users file path
miquel_fp <- "C:/Users/Miquel/Documents/GitHub/ADEI/"
xavi_fp <- "~/Documents/FIB/ADEI/ADEI/"
filepath <- xavi_fp
filepath <- miquel_fp
# Set working directory
setwd(filepath)

# Load data from file
load(paste0(filepath,"MyOldCars-5000Clean.RData"))

# Index reset
row.names(df) <- NULL
```

# PCA

We have done PCA in order to combine related variables, and focus on uncorrelated or independent ones, especially those along which the observations have high variance. Also, to obtain a smaller set of variables that explain most of the variance in the original data, in more compact and insightful form.

```{r}
names(df)
vars_con<-names(df)[c(5,7,8,11)]
vars_res<-names(df)[c(3,18)]
vars_dis<-names(df)[c(1,2,4,6,9,10,13,14,15,16,17)]

# Multivariant outliers should be included as supplementary observations
ll <- which( df$mout == "YesMOut")
res.pca<-PCA(df[,c(vars_res, vars_dis, vars_con)],quali.sup=c(2:13),quanti.sup=c(1),ind.sup=ll) 
```

As we can see in the first two plots tax and years_sell/mileage have almost an angle of 90 degrees, meaning that probably these variable are not that much related. Instead, years_sell and mileage are positively related. Price although it doesn't completely go in the opposite direction we can see that is inversely related to years_sell and mileage. 

## Eigenvalues and dominant axes analysis

```{r}
res.pca$eig[,1:3]
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 60))
```

The eigenvalue of the first component is larger than the other ones. Starting from the second component with an eigenvalue of 1.138... the consequent eigenvalues get smaller. 

According to the kaiser criteria we will use the first 2 dimensions (the ones with an eigenvalue > 1).

And according to Elbow's rule (based on selecting dimensions until the difference in variance of that of the next factorial plane is almost the same as that of the current plane) we can also use the first two dimensions (Dim.1 and Dim.2). The difference between the dimensions 2 and 3 is significantly less that the one we can see between dimensions 1 and 2. 

## Individuals point of view (contribution)

```{r}
fviz_contrib(res.pca, choice = "ind", axes = 1:2, top = 20)
```

As we can see from the Contribution of individuals to Dim-1-2 plot, the 20 most contributive individuals in descending order are 4570, 2703, 3254, 2199, 4662, 735, 4566, 1944, 99, 913, 4997, 80, 224, 2429, 2353, 1839, 239, 4596, 531 and 324. 

## Interpreting the axes

### Dimension 1

```{r}
fviz_contrib(res.pca, choice = "var", axes = 1)
fviz_cos2(res.pca, choice = "var", axes = 1)
```
The years_sell, mileage, mpg and tax variables have a positive first dimension.
Dimension 1 shows a positive correlation to years_sell and mileage. Price target variable (supplementary) is negatively associated to the first factorial axis. 
As we can see with cos2 years_sell and mileage are the best represented in the first dimension. 

### Dimension 2

```{r}
fviz_contrib(res.pca, choice = "var", axes = 2)
fviz_cos2(res.pca, choice = "var", axes = 2)
```
The tax, years_sell and mileage variables have a positive second dimension and the mpg variable has a negative second dimension. 
Dimension 2 shows the greatest positive correlation to tax and the lowest negative correlation to mpg. 
As we can see with cos2 tax is the best represented in the second dimension.


# Hierarchical Clustering

As we have seen previously in this report we should pick 2 clusters. But we will pick 7 because it distributes the data more proportionately among the clusters. But you also can see in the table below that the number of individuals for each cluster is still quite unbalanced. 

```{r}
res.pca<-PCA(df[,c(vars_res, vars_dis, vars_con)],quali.sup=c(2:13),quanti.sup= c(1), ind.sup = ll )
res.hcpc<-HCPC(res.pca,nb.clust=7,graph=T)

table(res.hcpc$data.clust$clust)
```

```{r}
res.hcpc$desc.var$test.chi2
res.hcpc$desc.var$category

```

We start wit the description of the categorical variables that characterize the clusters:
Cluster 1: Cluster one has cars with few years_sell, low mpg, medium taxes, low mileage and high price. Also, cars with semiAuto transmission and petrol as fuel predominate. We can say this because these categories are overrepresented in the cluster.
Cluster 2: Cluster two has cars with few years_sell, low mpg and medium taxes and high price. Also, cars with diesel as fuel and non-Audi cars predominate.
Cluster 3: Cluster three has cars with high taxes, few years_sell, low mpg and high mileage and medium price. Also, cars with petrol as fuel predominate.
Cluster 4: Cluster four has cars with high mpg, high mileage, few years_sell, low price and medium taxes. Also, cars with manual transmission and diesel as fuel predominate.
Cluster 5: Cluster five has cars high taxes, high years_sell, high mileage, low mpg and medium-high price.
Cluster 6: Cluster six has cars with low taxes, high mpg, high years_sell, high mileage and low price. Also, non-Audi cars predominate.
Cluster 7: Cluster seven has cars with high mileage, high years_sell, low price, high taxes and high mpg. Also, cars with diesel as fuel and cars with manual transmission predominate
Cluster 8: Cluster of multivariant outliers.

```{r}
res.hcpc$desc.var$quanti.var
res.hcpc$desc.var$quanti
```
Regarding quantitative variables:

Cluster 1: As we can see price mean is greater in cluster 1 than in the overall mean. Also, we can see that tax, mileage, years_sell and mpg means are lower in cluster 1 than in the overall means. So we can say that cluster 1 is a cluster of expensive cars with low tax, low mileage, few years_sell and low mpg.

Cluster 2: As we can see price and mpg means are greater in cluster 2 than in the overall means. Also, we can see that tax, mileage and years_sell means are lower in cluster 2 than in the overall means. So we can say that cluster 2 is a cluster of expensive cars with high mpg, low tax, low mileage and few years_sell.

Cluster 3: As we can see years_sell, mileage and tax means are greater in cluster 3 than in the overall means. Also, we can see that price and mpg means are lower in cluster 3 than in the overall means. So we can say that cluster 3 is a cluster of cheap cars with high years_sell, high mileage, high tax and low mpg.

Cluster 4: As we can see mpg, years_sell and mileage means are greater in cluster 4 than in the overall means. Also, we can see that tax and price means are lower in cluster 4 than in the overall means. So we can say that cluster 4 is a cluster of cheap cars with high mpg, many years_sell, high mileage and low tax.

Cluster 5: As we can see tax, years_sell and mileage means are greater in cluster 5 than in the overall means. Also, we can see that mpg mean is lower in cluster 5 than in the overall mean. So we can say that cluster 5 is a cluster of cars with high tax, many years_sell, high mileage and low mpg. 

Cluster 6: As we can see years_sell, mileage and mpg means are greater in cluster 6 than in the overall means. Also, we can see that price and tax means are lower in cluster 6 than in the overall means. So we can say that cluster 6 is a cluster of cheap cars with many years_sell, high mileage, high mpg and low tax.

Cluster 7: As we can see mileage, years_sell, mpg and tax means are greater in cluster 7 than in the overall means. Also, we can see that price mean is lower in cluster 7 than in the overall mean. So we can say that cluster 7 is a cluster of cheap cars with high mileage, many years_sell, high mpg and high tax.

Cluster 8: Cluster of multivariant outliers.

We have created a new variable indicating the cluster to which the individual belongs after the Hierarchical clustering. 
```{r}
df$claHC<-8
df[ row.names(res.hcpc$data.clust), "claHC" ]<-res.hcpc$data.clust$clust
df$claHC<-factor(df$claHC)
levels( df$claHC ) <- paste0("claHCPC-",levels( df$claHC ) )
```


# K-Means Classification
```{r}
res.pca<-PCA(df[,c(vars_res, vars_dis, vars_con)],quali.sup=c(2:13),quanti.sup= c(1), ind.sup = ll,ncp =2 )
ppcc<-res.pca$ind$coord[,1:2]
dim(ppcc)

dist<-dist(ppcc)
kc<-kmeans(dist,7, iter.max = 30, trace=T)

```

We have created a new variable indicating the cluster to which the individual belongs after the K-Means classification. 
```{r}
df$claKM<-8
df[ -ll, "claKM" ]<-kc$cluster
df$claKM<-factor(df$claKM)
# levels( df$claKM ) <- paste0("claKMPC-",levels( df$claKM ) )

kc$betweenss/kc$totss

names(df)
catdes(df,21)

```
Cluster 1: As we can see price mean is greater in cluster 1 than in the overall mean. Also, we can see that tax, mpg, mileage and years_sell means are lower in cluster 1 than in the overall means. So we can say that cluster 1 is the cluster of expensive cars with few/less tax, mpg, mileage and years_sell.(totalMOE negative)

Cluster 2: As we can see tax, years_sell and mileage means are greater in cluster 2 than in the overall means. Also, we can see that price and mpg means are lower in cluster 2 than in the overall means. So we can say that cluster 2 is the cluster of cars with high/great tax, years_sell and mileage and with few/less price and mpg. (totalMOE negative)

Cluster 3: As we can see mpg, years_sell and mileage means are greater in cluster 3 than in the overall means. Also, we can see that tax and price means are lower in cluster 3 than in the overall means. So we can say that cluster 3 is the cluster of cars with high/great mpg, years_sell and mileage and with few/less tax and price.(totalMOE positive)

Cluster 4: Cluster of multivariant outliers
As we can see mileage, years_sell and tax means are greater in cluster 4 than in the overall means. Also, we can see that mpg mean is lower in cluster 4 than in the overall mean. So we can say that cluster 4 is the cluster of cars with high/great mileage, years_sell and tax and with few/less mpg. (totalMOE positive)

# CA analysis 

```{r}
par(mfrow=c(1,1))


tt<-table(df[,c("aux_price","aux_tax")])
tt
res.ca<-CA(tt)
# lines(res.ca$row$coord[,1],res.ca$row$coord[,2],lwd=2,col="blue")
chisq.test(tt)

names(res.ca)
fviz_eig(res.ca) #Same outputs as PCA
summary(res.ca,dig=2)

plot( res.ca, cex=0.8, graph.type = "classic" )
lines( res.ca$row$coord[,1], res.ca$row$coord[,2], col="blue", lwd = 2 )
lines( res.ca$col$coord[,1], res.ca$col$coord[,2], col="red", lwd = 2 )
fviz_ca_biplot(res.ca,repel=TRUE)+theme_bw() 
```
As we can see aux_price and aux_tax variables are not independent because the p-value is less than 0.05.
Also, we can see that the cheapest cars have the highest taxes and the most expensive cars have average/medium taxes.


We have considered to impute hybrid cars because they cause noise.//Revisar
```{r}
par(mfrow=c(1,1))
#lh<-which(df$fuelTyp=="f.Fuel-Hybrid")
#df<-df[-lh,]
tt<-table(df[,c("aux_price","fuelType")])
tt
res.ca<-CA(tt)
plot( res.ca, cex=0.8, graph.type = "classic" )
lines( res.ca$row$coord[,1], res.ca$row$coord[,2], col="blue", lwd = 2 )
lines( res.ca$col$coord[,1], res.ca$col$coord[,2], col="red", lwd = 2 )
summary(res.ca)
chisq.test(tt)
```
As we can see aux_price and aux_tax variables are not independent because the p-value is less than 0.05.
Also, we can see that hybrid cars cause noise. We can see that diesel cars have the highest prices and petrol and other cars have the lowest prices. 

The objectives of MCA are close to PCA objectives: similarity among individuals/ similarity among variables. Also, generalization of CA objectives: relationships among the categories.

# MCA analysis:
```{r}
par(mfrow=c(1,1))
llvout<-which(df$mout=="YesMOut");length(llvout) #Multivariate outliers
res.mca<-MCA(df[,c(vars_dis[c(3:4,6:11)],"price", "Audi") ],quali.sup=c(4,10),quanti.sup=9 , ind.sup=llvout)
mean(res.mca$eig[,1])
summary(res.mca)
vars_dis
fviz_eig(res.mca)

sort(res.mca$ind$contrib[,1],decreasing=T)[1:6]
sort(res.mca$ind$contrib[,2],decreasing=T)[1:6]
sort(res.mca$ind$contrib[,3],decreasing=T)[1:6]
sort(res.mca$ind$contrib[,4],decreasing=T)[1:6]
sort(res.mca$ind$contrib[,5],decreasing=T)[1:6]
#sort(res.mca$ind$contrib[,6],decreasing=T)[1:6]
#sort(res.mca$ind$contrib[,7],decreasing=T)[1:6]
#sort(res.mca$ind$contrib[,8],decreasing=T)[1:6]
#sort(res.mca$ind$contrib[,9],decreasing=T)[1:6]

fviz_contrib(res.mca, choice = "ind", axes = 1:5, top = 20)#NOOOOOO EM DEIXA POSAR 1:9
vars_dis
```
According to Kaiser criteria (principal components with an eigenvalue > mean(eigenvalues)) we have to interpret 9 axes (Dim. 1 to Dim. 9).

The 6 most contributive individuals for 1 principal component axis in descending order are 1282, 1646, 1900, 1980, 2047 and 2048. 
The 6 most contributive individuals for 2 principal component axis in descending order are 3537, 3650, 3719, 3761, 3993 and 4543.
The 6 most contributive individuals for 3 principal component axis in descending order are 493, 851, 913, 1863, 425 and 492.
The 6 most contributive individuals for 4 principal component axis in descending order are 1529, 1544, 1866, 1998, 2013 and 1108.
The 6 most contributive individuals for 5 principal component axis in descending order are 1102, 1210, 1626, 1663, 1207 and 1401. 
The 6 most contributive individuals for 6 principal component axis in descending order are 
The 6 most contributive individuals for 7 principal component axis in descending order are 
The 6 most contributive individuals for 8 principal component axis in descending order are 
The 6 most contributive individuals for 9 principal component axis in descending order are 

Better explanation I think:
As we can see from the Contribution of individuals to Dim-1-5 plot, the 20 most contributive individuals in descending order are 1102, 1210, 1626, 1663, 1207, 1401, 1639, 1696, 1295, 1684, 1798, 1763, 1891, 1280, 1487, 1636, 1993, 1999, 1912 and 1530. 

We can see/distinguish four clouds of variables (variables in the same cloud means they are related):
First: manufacturer, transmission and fuelType variables.
Second: Audi variable. 
Third: aux_price, price, aux_mpg and aux_tax variables. 
Forth: aux_mileage and aux_years_sell variables. 

As we can see the cheapest cars are VW, have manual transmission, high taxes, medium years_sell, medium-high mileage and medium-high mpg.
As we can see the most expensive cars are Mercedes, hybrid, have automatic or semi-automatic transmission, medium taxes, few years_sell, low mileage and low mpg. 

As we can see Audi cars are petrol or other and have medium-low mpg. 

As we can see supplementary variable price is in the second quadrant which corresponds to the most expensive cars. 


# Hierarchical Clustering (from MCA)
```{r}
#5 dimensions 
res.mca<-MCA(df[,c(vars_dis[c(3:4,6:11)],"price") ],quali.sup=c(4,6),quanti.sup=9 , ind.sup=llvout, ncp = 5)
res.hcmc<-HCPC(res.mca,nb.clust=-1,order=TRUE)
names(res.hcmc)

res.hcmc$desc.var

df$clamHC<-4
df[ row.names(res.hcmc$data.clust), "clamHC" ]<-res.hcmc$data.clust$clust
df$clamHC<-factor(df$clamHC)
levels( df$clamHC ) <- paste0("claHCMC-",levels( df$clamHC ) )

res.hcmc$desc.ind$para
res.hcmc$desc.ind$dist

table(df$clamHC,df$claHC)
table(df$clamHC,df$claKM)

```
Cluster 1: We can say that cluster 1 is the cluster of expensive cars (overrepresented) with low mileage (overrepresented), low mpg (overrepresented), few years_sell (overrepresented) and medium taxes (overrepresented).

Cluster 2: We can say that cluster 2 is the cluster of cheap cars (overrepresented) with low taxes (overrepresented), medium-high mileage (overrepresented), medium years_sell (overrepresented) and high mpg (overrepresented).

Cluster 3: We can say that cluster 3 is the cluster of cheap cars (overrepresented) with high years_sell (overrepresented), high mileage (overrepresented), high mpg (overrepresented) and high taxes (overrepresented).  

Cluster 4: Cluster of multivariant outliers.

The parangons of cluster 1 are 4080, 4572, 4668, 4811 and 4837.
The parangons of cluster 2 are 4562, 4991, 4912, 140 and 610.
The parangons of cluster 3 are 3558, 4083, 4988, 3935 and 3962.

The dist/distants of cluster 1 are 1102, 1210, 1626, 1663 and 1207.
The dist/distants of cluster 2 are 1530, 1989, 2023, 1280 and 1487.
The dist/distants of cluster 3 are 2547, 3295, 469, 1807 and 1829.

