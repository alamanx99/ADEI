---
title: "USED CAR PRICES CASE STUDY"
subtitle: 'Deliverable 2: PCA, CA and Clustering'
author: "Miquel Parra i Xavier Alaman"
date: \today
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
geometry: left=1.9cm,right=1.9cm,top=1.25cm,bottom=1.52cm
fontsize: 18pt
classoption: a4paper
editor_options: 
  chunk_output_type: console
---

# R libraries imports, useful functions and data loading

In this first section we will load all required packages and libraries, declare additional functions, and load our data.

## Load Required Packages

```{r, message=FALSE, warning=FALSE, results='hide'}
# Load Required Packages: to be increased over the course
options(contrasts=c("contr.treatment","contr.treatment"))

requiredPackages <- c("effects","FactoMineR","car","missMDA","mvoutlier","chemometrics", "factoextra","RColorBrewer","ggplot2","dplyr","ggmap","ggthemes","knitr")

#use this function to check if each package is on the local machine
#if a package is installed, it will be loaded
#if any are not, the missing package(s) will be installed and loaded
package.check <- lapply(requiredPackages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)
  }
})
#verify they are loaded
search()

```

## Sample load

```{r, results='hide'}
# Clear plots
if(!is.null(dev.list())) dev.off()

# Clean workspace
rm(list=ls())

# Users file path
miquel_fp <- "C:/Users/Miquel/Documents/GitHub/ADEI/"
xavi_fp <- "~/Documents/FIB/ADEI/ADEI/"
filepath <- xavi_fp

# Set working directory
setwd(filepath)

# Load data from file
load(paste0(filepath,"MyOldCars-5000Clean.RData"))

# Index reset
row.names(df) <- NULL
```

# PCA

We have done PCA in order to combine related variables, and focus on uncorrelated or independent ones, especially those along which the observations have high variance. Also, to obtain a smaller set of variables that explain most of the variance in the original data, in more compact and insightful form.

```{r}
names(df)
vars_con<-names(df)[c(5,7,8,11)]
vars_res<-names(df)[c(3,18)]
vars_dis<-names(df)[c(1,2,4,6,9,10,13,14,15,16,17)]

# Multivariant outliers should be included as supplementary observations
ll <- which( df$mout == "YesMOut")
res.pca<-PCA(df[,c(vars_res, vars_dis, vars_con)],quali.sup=c(2:13),quanti.sup=c(1),ind.sup=ll) 
```

As we can see in the first two plots tax and years_sell/mileage have almost an angle of 90 degrees, meaning that probably these variable are not that much related. Instead, years_sell and mileage are positively related. Price although it doesn't completely go in the opposite direction we can see that is inversely related to years_sell and mileage. 

## Eigenvalues and dominant axes analysis

```{r}
res.pca$eig[,1:3]
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 60))
```

The eigenvalue of the first component is larger than the other ones. Starting from the second component with an eigenvalue of 1.138... the consequent eigenvalues get smaller. 

According to the kaiser criteria we will use the first 2 dimensions (the ones with an eigenvalue > 1).

And according to Elbow's rule (based on selecting dimensions until the difference in variance of that of the next factorial plane is almost the same as that of the current plane) we can also use the first two dimensions (Dim.1 and Dim.2). The difference between the dimensions 2 and 3 is significantly less that the one we can see between dimensions 1 and 2. 

With the two dimensions we capture/retain an 81.76% of the total variance. 

## Individuals point of view (contribution)

```{r}
fviz_contrib(res.pca, choice = "ind", axes = 1:2, top = 20)
```

As we can see from the Contribution of individuals to Dim-1-2 plot, the 20 most contributive individuals in descending order are 4570, 2703, 3254, 2199, 4662, 735, 4566, 1944, 99, 913, 4997, 80, 224, 2429, 2353, 1839, 239, 4596, 531 and 324. 

## Interpreting the axes

### Dimension 1

```{r}
fviz_contrib(res.pca, choice = "var", axes = 1)
fviz_cos2(res.pca, choice = "var", axes = 1)
```
The years_sell, mileage, mpg and tax variables have a positive first dimension.
Dimension 1 shows a positive correlation to years_sell and mileage. Price target variable (supplementary) is negatively associated to the first factorial axis. 
As we can see with cos2 years_sell and mileage are the best represented in the first dimension. 

### Dimension 2

```{r}
fviz_contrib(res.pca, choice = "var", axes = 2)
fviz_cos2(res.pca, choice = "var", axes = 2)
```
The tax, years_sell and mileage variables have a positive second dimension and the mpg variable has a negative second dimension. 
Dimension 2 shows the greatest positive correlation to tax and the lowest negative correlation to mpg. 
As we can see with cos2 tax is the best represented in the second dimension.


# Hierarchical Clustering

As we have seen previously in this report we should pick 2 clusters. But we will pick 7 because it distributes the data more proportionately among the clusters. But you also can see in the table below that the number of individuals for each cluster is still quite unbalanced. 

```{r}
res.pca<-PCA(df[,c(vars_res, vars_dis, vars_con)],quali.sup=c(2:13),quanti.sup= c(1), ind.sup = ll )
res.hcpc<-HCPC(res.pca,nb.clust=7,graph=T)

table(res.hcpc$data.clust$clust)
```

```{r}
res.hcpc$desc.var$test.chi2
res.hcpc$desc.var$category

```

We start with the description of the categorical variables that characterize the clusters:

Cluster 1: Cluster one has cars with few years_sell, low mpg, medium taxes, low mileage and high price. Also, cars with semiAuto transmission and cars with petrol as fuel predominate. We can say this because these categories are overrepresented in the cluster.

Cluster 2: Cluster two has cars with few years_sell, low mpg and medium taxes and high price. Also, cars with diesel as fuel and non-Audi cars predominate.

Cluster 3: Cluster three has cars with high taxes, few years_sell, low mpg and high mileage and medium price. Also, cars with petrol as fuel predominate.

Cluster 4: Cluster four has cars with high mpg, high mileage, few years_sell, low price and medium taxes. Also, cars with manual transmission and cars with diesel as fuel predominate.

Cluster 5: Cluster five has cars high taxes, high years_sell, high mileage, low mpg and medium-high price.

Cluster 6: Cluster six has cars with low taxes, high mpg, high years_sell, high mileage and low price. Also, non-Audi cars predominate.

Cluster 7: Cluster seven has cars with high mileage, high years_sell, low price, high taxes and high mpg. Also, cars with diesel as fuel and cars with manual transmission predominate.

Cluster 8: Cluster of multivariant outliers.

```{r}
res.hcpc$desc.var$quanti.var
res.hcpc$desc.var$quanti
```
Regarding quantitative variables:

Cluster 1: As we can see price mean is greater in cluster 1 than in the overall mean. Also, we can see that tax, mileage, years_sell and mpg means are lower in cluster 1 than in the overall means. So we can say that cluster 1 is a cluster of expensive cars with low tax, low mileage, few years_sell and low mpg.

Cluster 2: As we can see price and mpg means are greater in cluster 2 than in the overall means. Also, we can see that tax, mileage and years_sell means are lower in cluster 2 than in the overall means. So we can say that cluster 2 is a cluster of expensive cars with high mpg, low tax, low mileage and few years_sell.

Cluster 3: As we can see years_sell, mileage and tax means are greater in cluster 3 than in the overall means. Also, we can see that price and mpg means are lower in cluster 3 than in the overall means. So we can say that cluster 3 is a cluster of cheap cars with high years_sell, high mileage, high tax and low mpg.

Cluster 4: As we can see mpg, years_sell and mileage means are greater in cluster 4 than in the overall means. Also, we can see that tax and price means are lower in cluster 4 than in the overall means. So we can say that cluster 4 is a cluster of cheap cars with high mpg, many years_sell, high mileage and low tax.

Cluster 5: As we can see tax, years_sell and mileage means are greater in cluster 5 than in the overall means. Also, we can see that mpg mean is lower in cluster 5 than in the overall mean. So we can say that cluster 5 is a cluster of cars with high tax, many years_sell, high mileage and low mpg. 

Cluster 6: As we can see years_sell, mileage and mpg means are greater in cluster 6 than in the overall means. Also, we can see that price and tax means are lower in cluster 6 than in the overall means. So we can say that cluster 6 is a cluster of cheap cars with many years_sell, high mileage, high mpg and low tax.

Cluster 7: As we can see mileage, years_sell, mpg and tax means are greater in cluster 7 than in the overall means. Also, we can see that price mean is lower in cluster 7 than in the overall mean. So we can say that cluster 7 is a cluster of cheap cars with high mileage, many years_sell, high mpg and high tax.

Cluster 8: Cluster of multivariant outliers.

We have created a new variable indicating the cluster to which the individual belongs after the Hierarchical clustering. 
```{r}
df$claHC<-8
df[ row.names(res.hcpc$data.clust), "claHC" ]<-res.hcpc$data.clust$clust
df$claHC<-factor(df$claHC)
levels( df$claHC ) <- paste0("claHCPC-",levels( df$claHC ) )
```


# K-Means Classification
```{r}
res.pca<-PCA(df[,c(vars_res, vars_dis, vars_con)],quali.sup=c(2:13),quanti.sup= c(1), ind.sup = ll,ncp =2 )
ppcc<-res.pca$ind$coord[,1:2]
dim(ppcc)
```

```{r, message=FALSE, warning=FALSE, results='hide'}}
dist<-dist(ppcc)
kc<-kmeans(dist,7, iter.max = 30, trace=T)
```

We have created a new variable indicating the cluster to which the individual belongs after the K-Means classification. 
```{r}
df$claKM<-8
df[ -ll, "claKM" ]<-kc$cluster
df$claKM<-factor(df$claKM)

kc$betweenss/kc$totss
```


```{r}
catdes(df,21)
```
We start with the description of the categorical variables that characterize the clusters:

Cluster 1: Cluster one has cars with few years_sell, low mpg, medium taxes, low mileage and high price. Also, cars with semiAuto transmission and cars with petrol as fuel predominate. We can say this because these categories are overrepresented in the cluster.

Cluster 1: Cluster one has cars with high mileage and many years_sell. Also, non-Audi cars predominate.

Cluster 2: Cluster two has cars with medium years_sell, high mpg, low price and medium-high mileage . Also, cars with diesel as fuel predominate.

Cluster 3: Cluster three has cars with high taxes, many years_sell, high mileage and low mpg. Also, non-Audi cars and cars with engineSize 2 predominate. 

Cluster 4: Cluster four has cars with few years_sell, medium taxes, low mileage, high price and medium-low mpg. Also, non-Audi cars and cars with diesel as fuel predominate.

Cluster 5: Cluster five has cars with high mileage, many years_sell, low price, high taxes and high mpg. Also, cars with diesel as fuel and cars with manual transmission predominate.

Cluster 6: Cluster six has cars with low mpg, few years_sell, low mileage, high price and medium taxes. Also, cars with petrol as fuel, cars with semiAuto transmission, cars with engineSize 2 and non-Audi cars predominate.

Cluster 7: Cluster seven has cars with medium-few years_sell, medium taxes, medium mileage, medium price and medium mpg. Also, non-Audi cars predominate.

Cluster 8: Cluster of multivariant outliers.

Regarding quantitative variables:

Cluster 1: As we can see mpg, years_sell and mileage means are greater in cluster 1 than in the overall means. Also, we can see that price and tax means are lower in cluster 1 than in the overall means. So we can say that cluster 1 is a cluster of cheap cars with high mpg, many years_sell, high mileage and low tax.

Cluster 2: As we can see mpg and years_sell means are greater in cluster 2 than in the overall means. Also, we can see that tax and price means are lower in cluster 2 than in the overall means. So we can say that cluster 2 is a cluster of cheap cars with high mpg, many years_sell and low tax.

Cluster 3: As we can see tax, years_sell and mileage means are greater in cluster 3 than in the overall means. Also, we can see that mpg mean is lower in cluster 3 than in the overall mean. So we can say that cluster 3 is a cluster of cars with high tax, many years_sell, high mileage and low mpg.

Cluster 4: As we can see price mean is greater in cluster 4 than in the overall mean. Also, we can see that tax, mpg, mileage and years_sell means are lower in cluster 4 than in the overall means. So we can say that cluster 4 is a cluster of expensive cars with low tax, low mpg, low mileage and few years_sell.

Cluster 5: As we can see mileage, years_sell and mpg means are greater in cluster 5 than in the overall means. Also, we can see that price mean is lower in cluster 5 than in the overall mean. So we can say that cluster 5 is a cluster of cheap cars with high mileage, many years_sell and high mpg.

Cluster 6: As we can see price mean is greater in cluster 6 than in the overall mean. Also, we can see that tax, mileage, years_sell and mpg means are lower in cluster 6 than in the overall means. So we can say that cluster 6 is a cluster of expensive cars and low tax, low mileage, few years_sell and low mpg.

Cluster 7: As we can see mpg mean is greater in cluster 7 than in the overall mean. Also, we can see that tax, years_sell and mileage means are lower in cluster 7 than in the overall means. So we can say that cluster 7 is a cluster of cars with high mpg, low tax, few years_sell and low mileage.

Cluster 8: Cluster of multivariate outliers.

# CA  

```{r}
par(mfrow=c(1,1))

tt<-table(df[,c("aux_price","aux_tax")])
tt
res.ca<-CA(tt)
chisq.test(tt)

fviz_eig(res.ca) #Same outputs as PCA
summary(res.ca,dig=2)

plot( res.ca, cex=0.8, graph.type = "classic" )
lines( res.ca$row$coord[,1], res.ca$row$coord[,2], col="blue", lwd = 2 )
lines( res.ca$col$coord[,1], res.ca$col$coord[,2], col="red", lwd = 2 )
fviz_ca_biplot(res.ca,repel=TRUE)+theme_bw() 
```

As we can see aux_price and aux_tax variables are not independent because the p-value is less than 0.05.
Also, we can see that the cheapest cars have the highest taxes and the most expensive cars have average/medium taxes.

# MCA 

The objectives of MCA are close to PCA objectives: similarity among individuals/ similarity among variables. Also, generalization of CA objectives: relationships among the categories.

```{r}
par(mfrow=c(1,1))
llvout<-which(df$mout=="YesMOut");length(llvout) #Multivariate outliers
res.mca<-MCA(df[,c(vars_dis[c(3:4,6:11)],"price", "Audi") ],quali.sup=c(4,10),quanti.sup=9 , ind.sup=llvout)
```

We can see that supplementary variable price is in the second quadrant (i.e. has a negative first dimension and a positive second dimension). 

## Eigenvalues and dominant axes analysis
```{r}
mean(res.mca$eig[,1])
summary(res.mca)
fviz_eig(res.mca)
```
according to Elbow's rule we can pick up to 4 dimensions, the ones that brings more variability among planes.

## Individuals point of view
```{r}
fviz_contrib(res.mca, choice = "ind", axes = 1:4, top = 10)
```

As we can see from the Contribution of individuals to Dim-1-2-3-4 plot, the 10 most contributive individuals in descending order are 1096 1635 2032 2041 1529 1544 1866 1998 2013 1086

## Interpreting map of categories

```{r}
fviz_mca_var(res.mca, repel=TRUE)
```

As we can see all the categories are sparse around the center of mass. In the first dimension we have as extremes f.years_sell-[2,3],
f.mileage-[4,6e+03] in the negative side and in the other one we have f.years_sell-(6,23], f.mpg-(61.4,88.3). For the dimension 2 as 
extremes we can find f.Fuel-Hybrid and f.Fuel-Other. This extreames they are going to be poorly repsented in that dimensions. 

## Interpreting the axes association to factor map

We can see/distinguish four clouds of variables (variables in the same cloud means they are related):
First: manufacturer, transmission and fuelType variables.
Second: Audi variable. 
Third: aux_price, price, aux_mpg and aux_tax variables. 
Forth: aux_mileage and aux_years_sell variables. 

As we can see the cheapest cars are VW, have manual transmission, high taxes, medium years_sell, medium-high mileage and medium-high mpg.
As we can see the most expensive cars are Mercedes, hybrid, have automatic or semi-automatic transmission, medium taxes, few years_sell, low mileage and low mpg. 

As we can see Audi cars are petrol or other and have medium-low mpg. 

As we can see supplementary variable price is in the second quadrant (i.e. has a negative first dimension and a positive second dimension) which corresponds to the most expensive cars. 


## Hierarchical Clustering (from MCA)
```{r}
res.mca<-MCA(df[,c(vars_dis[c(3:4,6:11)],"price") ],quali.sup=c(4,6),quanti.sup=9 , ind.sup=llvout, ncp = 4)
res.hcmc<-HCPC(res.mca,nb.clust=7,order=TRUE)
res.hcmc$desc.var
```

We start with the description of the categorical variables that characterize the clusters:

Cluster 1: Cluster one has cars with few years_sell, low mpg, medium taxes, low mileage and high price. Also, cars with semiAuto transmission and cars with petrol as fuel predominate. We can say this because these categories are overrepresented in the cluster.

Cluster 1: Cluster one has cars with low mpg, few years_sell, high price, low mileage and medium taxes. Also, cars with semiAuto transmission and cars with petrol as fuel predominate.

Cluster 2: Cluster two has cars with years_sell, low mileage, medium-low mpg and medium price. Also, cars with Manual transmission, VW cars and cars with petrol as fuel predominate.
 
Cluster 3: Cluster three has cars with few years_sell, high price, medium taxes and low mileage. Also, cars with diesel as fuel, Mercedes cars and cars with semiAuto transmission predominate.

Cluster 4: Cluster four has cars medium-high mpg. Also, BMW cars, cars with Hybrid as fuel and cars with Automatic transmission predominate.

Cluster 5: Cluster five has cars with medium years_sell, low price and medium-high mileage. Also, cars with petrol as fuel, VW cars and cars with Manual transmission predominate.

Cluster 6: Cluster six has cars with medium years_sell, medium taxes and medium-high mileage.
Also, cars with diesel as fuel and Mercedes cars predominate.

Cluster 7: Cluster seven has cars with many years_sell, high mileage, low price and high taxes.
Also, cars with diesel as fuel and cars with Manual transmission predominate.

Cluster 8: Cluster of multivariant outliers.

Regarding quantitative variables:

Cluster 1: As we can see price mean is greater in cluster 1 than in the overall mean. So we can say that cluster 1 is a cluster of expensive cars.

Cluster 2: As we can see price mean is lower in cluster 2 than in the overall mean. So we can say that cluster 2 is a cluster of cheap cars.

Cluster 3: As we can see price mean is greater in cluster 3 than in the overall mean. So we can say that cluster 3 is a cluster of expensive cars.

Cluster 4: 

Cluster 5: As we can see price mean is lower in cluster 5 than in the overall mean. So we can say that cluster 5 is a cluster of cheap cars.

Cluster 6: As we can see price mean is lower in cluster 6 than in the overall mean. So we can say that cluster 6 is a cluster of cheap cars.

Cluster 7: As we can see price mean is lower in cluster 7 than in the overall mean. So we can say that cluster 7 is a cluster of cheap cars.

Cluster 8: Cluster of multivariant outliers.


```{r}
res.hcmc$desc.ind$para
res.hcmc$desc.ind$dist
```
The parangons of cluster 1 are 160, 426, 432, 471 and 501.
The parangons of cluster 2 are 3498, 3508, 3516, 3517 and 3518.
The parangons of cluster 3 are 2532, 2148, 2348, 2388 and 2403.
The parangons of cluster 4 are 1798, 1566, 1910, 1912 and 1196.
The parangons of cluster 5 are 3321, 3374, 3643, 3814 and 36.
The parangons of cluster 6 are 2167, 2239, 2265, 2650 and 2686.
The parangons of cluster 7 are 3558, 4083, 4988, 3278 and 4094.

The dist/distants of cluster 1 are 35, 40, 46, 69 and 91.
The dist/distants of cluster 2 are 4487, 4010, 4663, 4009 and 4026.
The dist/distants of cluster 3 are 2266, 2274, 2285, 2287 and 2384.
The dist/distants of cluster 4 are 1530, 1989, 2023, 1910 and 1102.
The dist/distants of cluster 5 are 4011, 174, 317, 1 and 73.
The dist/distants of cluster 6 are 1092, 1279, 1529, 1544 and 1866.
The dist/distants of cluster 7 are 3552, 3575, 3590, 3618 and 3647. 

We have created a new variable indicating the cluster to which the individual belongs after the Hierarchical clustering. 
```{r}
df$clamHC<-8
df[ row.names(res.hcmc$data.clust), "clamHC" ]<-res.hcmc$data.clust$clust
df$clamHC<-factor(df$clamHC)
levels( df$clamHC ) <- paste0("claHCMC-",levels( df$clamHC ) )
```

## Comparisons
```{r}
table(df$clamHC,df$claHC)
table(df$clamHC,df$claKM)

```


