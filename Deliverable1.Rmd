---
title: "USED CAR PRICES CASE STUDY"
subtitle: 'Deliverable I: Data Processing, Description, Validation and Profiling'
author: "Miquel Parra i Xavier Alaman"
date: \today
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
geometry: left=1.9cm,right=1.9cm,top=1.25cm,bottom=1.52cm
fontsize: 18pt
classoption: a4paper
editor_options: 
  chunk_output_type: console
---

# R libraries imports, useful functions and data loading

In this first section we will load all required packages and libraries, declare additional functions, and load our data.

## Load Required Packages

```{r}
# Load Required Packages: to be increased over the course
options(contrasts=c("contr.treatment","contr.treatment"))

requiredPackages <- c("effects","FactoMineR","car","missMDA","mvoutlier","chemometrics", "factoextra","RColorBrewer","ggplot2","dplyr","ggmap","ggthemes","knitr")

#use this function to check if each package is on the local machine
#if a package is installed, it will be loaded
#if any are not, the missing package(s) will be installed and loaded
package.check <- lapply(requiredPackages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)
  }
})
#verify they are loaded
search()

```

## Sample load

```{r, results='hide'}
# Clear plots
if(!is.null(dev.list())) dev.off()

# Clean workspace
rm(list=ls())

# Users file path
miquel_fp <- "C:/Users/Miquel/Documents/GitHub/ADEI/"
xavi_fp <- "~/Documents/FIB/ADEI/ADEI/"
filepath <- xavi_fp
filepath <-miquel_fp

# Set working directory
setwd(filepath)

# Load data from file
load(paste0(filepath,"MyOldCars-5000Clean.RData"))

# Index reset
row.names(df) <- NULL
```

## PCA

We have done PCA in order to combine related variables, and focus on uncorrelated or independent ones, especially those along which the observations have high variance. Also, to obtain a smaller set of variables that explain most of the variance in the original data, in more compact and insightful form.
```{r}
names(df)
vars_con<-names(df)[c(5,7,8,11)]
vars_res<-names(df)[c(3,18)]
vars_dis<-names(df)[c(1,2,4,6,9,10,13,14,15,16,17)]

vars_con
vars_res
vars_dis

# Multivariant outliers should be included as supplementary observations
ll <- which( df$mout == "YesMOut")
res.pca<-PCA(df[,c(vars_res, vars_dis, vars_con)],quali.sup=c(2:13),quanti.sup= c(1), ind.sup = ll ) 

summary(res.pca)
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 60))

sort(res.pca$ind$contrib[,1],decreasing=T)[1:6]
sort(res.pca$ind$contrib[,2],decreasing=T)[1:6]
sort(res.pca$ind$contrib[,1:2],decreasing=T)[1:6]

sort(res.pca$var$contrib[,1],decreasing=T)[1:3]
sort(res.pca$var$cos2[,1],decreasing=T)[1:3]
sort(res.pca$var$coord[,1],decreasing=T)[1:4]
sort(res.pca$var$contrib[,2],decreasing=T)[1:3]
sort(res.pca$var$cos2[,2],decreasing=T)[1:3]
sort(res.pca$var$coord[,2],decreasing=T)[1:4]
```
According to Kaiser criteria we have to interpret two axes (Dim.1 and Dim.2).
According to Elbow's rule we have to interpret two axes (Dim.1 and Dim.2).
The 6 most contributive individuals for 1 principal component axis in descending order are 2323, 2074, 1027, 488, 1138 and 3933.
The 6 most contributive individuals for 2 principal component axis in descending order are 2703, 4570, 2429, 1839, 239 and 324. 

The 3 most contributive variables for 1 principal component axis in descending order are years_sell, mileage and mpg. 
The 3 most contributive variables for 2 principal component axis in descending order are tax, mpg and years_sell.

The 3 best represented variables for 1 principal component axis in descending order are years_sell, mileage and mpg. 
The 3 best represented variables for 2 principal component axis in descending order are tax, mpg and years_sell.

The years_sell, mileage, mpg and tax variables have a positive first dimension.
The tax, years_sell and mileage variables have a positive second dimension and the mpg variable has a negative second dimension. 

Dimension 1 shows a positive correlation to years_sell and mileage. Price target variable (supplementary) is negatively associated to the first factorial axis. 
Dimension 2 shows the greatest positive correlation to tax and the lowest negative correlation to mpg. 

##Hierarchical Clustering
```{r}
# 2 dimensions have to be selected according to Kaiser's criteria
res.pca<-PCA(df[,c(vars_res, vars_dis, vars_con)],quali.sup=c(2:13),quanti.sup= c(1), ind.sup = ll,ncp =2 )
res.hcpc<-HCPC(res.pca,nb.clust=-1,graph=T)
res.hcpc$desc.var

df$claHC<-4
df[ row.names(res.hcpc$data.clust), "claHC" ]<-res.hcpc$data.clust$clust
df$claHC<-factor(df$claHC)
levels( df$claHC ) <- paste0("claHCPC-",levels( df$claHC ) )
```
Cluster 1: As we can see price mean is greater in cluster 1 than in the overall mean. Also, we can see that tax, mpg, mileage and years_sell means are lower in cluster 1 than in the overall means. 
So we can say that cluster 1 is the cluster of expensive cars with few/less tax, mpg, mileage and years_sell.

Cluster 2: As we can see tax, years_sell and mileage means are greater in cluster 2 than in the overall means. Also, we can see that mpg mean in cluster 2 is lower than in the overall mean. 
So we can say that cluster 2 is the cluster of cars with high/great tax, years_sell and mileage and with few/less mpg. 

Cluster 3: As we can see years_sell, mileage and mpg means are greater in cluster 3 than in the overall means. Also, we can see that tax and price means are lower in cluster 3 than in the overall means. 
So we can say that cluster 3 is the cluster of cars with high/great years_sell, mileage and mpg and with less/few tax and price. 

Cluster 4: Cluster of multivariant outliers. 

##K-Means Classification
```{r}
res.pca<-PCA(df[,c(vars_res, vars_dis, vars_con)],quali.sup=c(2:13),quanti.sup= c(1), ind.sup = ll,ncp =2 )
ppcc<-res.pca$ind$coord[,1:2]
dim(ppcc)

dist<-dist(ppcc)
kc<-kmeans(dist,3, iter.max = 30, trace=T)

df$claKM<-4
df[ -ll, "claKM" ]<-kc$cluster
df$claKM<-factor(df$claKM)
# levels( df$claKM ) <- paste0("claKMPC-",levels( df$claKM ) )

kc$betweenss/kc$totss

names(df)
catdes(df,21)

table(df$claHC,df$claKM)
```
Cluster 1: As we can see price mean is greater in cluster 1 than in the overall mean. Also, we can see that tax, mpg, mileage and years_sell means are lower in cluster 1 than in the overall means. So we can say that cluster 1 is the cluster of expensive cars with few/less tax, mpg, mileage and years_sell.(totalMOE negative)

Cluster 2: As we can see tax, years_sell and mileage means are greater in cluster 2 than in the overall means. Also, we can see that price and mpg means are lower in cluster 2 than in the overall means. So we can say that cluster 2 is the cluster of cars with high/great tax, years_sell and mileage and with few/less price and mpg. (totalMOE negative)

Cluster 3: As we can see mpg, years_sell and mileage means are greater in cluster 3 than in the overall means. Also, we can see that tax and price means are lower in cluster 3 than in the overall means. So we can say that cluster 3 is the cluster of cars with high/great mpg, years_sell and mileage and with less/few tax and price.(totalMOE positive)

Cluster 4: Cluster of multivariant outliers
As we can see mileage, years_sell and tax means are greater in cluster 4 than in the overall means. Also, we can see that mpg mean is lower in cluster 4 than in the overall mena. So we can say that cluster 4 is the cluster of cars with high/great mileage, years_sell and tax and with less/few mpg. (totalMOE positive)

##CA analysis for your data should contain your factor version of the numeric target (previous) in K= 7 (maximum 10) levels and 2 factors:

##MCA analysis for your data should contain:

##Hierarchical Clustering (from MCA)
